{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://akademie.datamics.com/kursliste/\">![title](bg_datamics_top.png)</a>\n",
    "\n",
    "<center><em>© Datamics</em></center><br><center><em>Besuche uns für mehr Informationen auf <a href='https://akademie.datamics.com/kursliste/'>www.akademie.datamics.com</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optischer Fluss (Optical Flow)\n",
    "\n",
    "----\n",
    "#### BEACHTE: Es ist wahrscheinlich eine gute Idee, den Kernel neu zu starten, wenn du diese Zellen jemals ausführen solltest, da der Tracking algorithm (Folgealgorithmus) manchmal in einer Schleife mit der Kamera hängenbleibt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lucas-Kanade Optischer Fluss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für ShiTomasi-Corner Detection (Eckenerkennung) (Paper Good Features to Track)\n",
    "corner_track_params = dict(maxCorners = 10,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter für den Lucas Kanade Optischen Fluss\n",
    "\n",
    "Erkenne die Bewegung spezifischer Punkte oder die aggregierte Bewegung ganzer Bereiche durch Anpassung des winSize-Argumentes. Dieses Argument bestimmt die Grösse des Integrationsfensters (Integration Window). Kleine Fenster sind anfälliger für Störsignale und können größere Bewegungen übersehen. Große Fenster \"überleben\" einen Einschluss (occlusion).\n",
    "\n",
    "Die Integration erscheint glatter mit einer größeren Fenstergröße.\n",
    "\n",
    "criteria hat hier zwei Werte - die maximale Anzahl von Iterationen (unter 10) und Epsilon (unter 0.03). Mehr Iterationen bedeuten eine erschöpfende Suche und ein kleineres Epsilon terminiert früher. Diese Argumente sind hauptsächlich nützlich beim Abwägen von Geschwindigkeit gegen Genauigkeit, bleiben aber meistens gleich.\n",
    "\n",
    "Wenn maxLevel den Wert 0 hat, ist es der gleiche Algorithmus, aber ohne der Verwendung von Pyramiden (entspricht calcOpticalFlowLK). Pyramiden erlauben es, optische Flüsse für verschiedene Auflösungen des Bildes zu finden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für Lucas Kanade Optischen Fluss\n",
    "lk_params = dict( winSize  = (200,200),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10,0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeichne das Video auf\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Nimm das erste Frame (Einzelbild) des Streams\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Konvertiere es in Graustufen (Wir bezeichnen dies im folgenden als das vorherige Frame)\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Finde die Ecken\n",
    "prevPts = cv2.goodFeaturesToTrack(prev_gray, mask = None, **corner_track_params)\n",
    "\n",
    "# Erzeuge eine passende Maske des vorherigen Frames, um später darauf zu zeichnen\n",
    "mask = np.zeros_like(prev_frame)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # Nimm das derzeitige Frame\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    # Konvertiere es in Graustufen\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Berechne den optischen Fluss des Graustufenbildes\n",
    "    nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray, frame_gray, prevPts, None, **lk_params)\n",
    "    \n",
    "    # Verwende den zurückgegebenen Statusarray (die Statusausgabe)\n",
    "    # Statusausgabe Statusvektor (chars ohne Vorzeichen); jedes Element des Vektors ist auf 1 gesetzt wenn\n",
    "    # der Fluss der korrespondierenden Merkmale gefunden wurde, andernfalls ist es auf 0 gesetzt.\n",
    "    good_new = nextPts[status==1]\n",
    "    good_prev = prevPts[status==1]\n",
    "    \n",
    "    # Verwende ravel, um Punkte zum Zeichnen von Linien und Kreisen zu erhalten\n",
    "    for i,(new,prev) in enumerate(zip(good_new,good_prev)):\n",
    "        \n",
    "        x_new,y_new = new.ravel()\n",
    "        x_prev,y_prev = prev.ravel()\n",
    "        \n",
    "        # Linien werden gezeichnet mit der vom ersten Frame erzeugten Maske\n",
    "        mask = cv2.line(mask, (x_new,y_new),(x_prev,y_prev), (0,255,0), 3)\n",
    "        \n",
    "        # Zeichne rote Kreise in Eckpunkte\n",
    "        frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1)\n",
    "    \n",
    "    # Zeige das Bild an, zusammen mit der Maske, auf die wir die Linie gezeichnet haben.\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "   \n",
    "    # Aktualisiere jetzt das vorherige Frame und vorherige Punkte\n",
    "    prev_gray = frame_gray.copy()\n",
    "    prevPts = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dichter Optischer Fluss (Dense Optical Flow) in OpenCV\n",
    "\n",
    "calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow\n",
    "\n",
    "Diese Funktion berechnet einen dichten Optischen Fluss mit dem Gunnar Farneback Algorithmus.\n",
    "\n",
    "Hier sind die Parameter der Funktion und was sie repräsentieren:\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* prev Erstes 8-bit Einkanal-Eingabebild.\n",
    "* next Zweites Eingabebild mit gleicher Größe und gleichem Typ.\n",
    "* flow Berechnetes Flussbild mit der selben Größe wie prev und dem Typ CV_32FC2.\n",
    "* pyr_scale spezifiziert die Skalierung des Bildes (<1) für den Bau von Pyramiden für jedes Bild\n",
    "  * pyr_scale=0.5 klassische Pyramide, bei der jede Ebene halb so groß ist wie die vorherige.\n",
    "* levels Anzahl von Pyramidenebenen inklusive der initialen Ebene; levels=1 bedeutet, dass keine weiteren Ebenen erzeugt werden und nur die Originalbilder verwendet werden.\n",
    "* winsize durchschnittliche Fenstergröße\n",
    "    * größere Werte erhöhen die Robustheit des Algorithmus gegenüber Störsignalen im Bild und die Chance zur Erkennung schneller Bewegungen, erzeugen aber ein verschwommeneres Bewegungsfeld.\n",
    "* iterations Anzahl von Iterationen, die der Algorithmus auf jeder Ebene der Pyramide durchführt.\n",
    "* poly_n Verwendete Nachbarschaftsgröße für Pixel zum Finden der polynomialen Erweiterung jedes Pixels\n",
    "    * größere Werte bedeuten, dass das Bild mit glatteren Oberflächen assoziiert wird, wodurch der Algorithmus robuster, aber das Bewegungsfeld auch verschwommener wird, normalerweise poly_n=5 oder 7.\n",
    "* poly_sigma Standardabweichung der gauß'schen Funktion, die zur Glättung der Ableitungen als Basis für die polynomiale Erweiterung verwendet wird; für poly_n=5 kannst du poly_sigma=1.1 verwenden, für poly_n=7 wäre poly_sigma=1.5 ein guter Wert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# Zeichne das Video auf\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame1 = cap.read()\n",
    "\n",
    "# Nimm die Graustufenversion des ersten Frames\n",
    "prvsImg = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv_mask = np.zeros_like(frame1)\n",
    "hsv_mask[:,:,1] = 255\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    nextImg = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Wirf einen Blick in die obige Markdown-Zelle für eine Zusammenfassung dieser Parameter, die meisten sind nur die vorgeschlagenen Standardwerte\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvsImg,nextImg, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    \n",
    "    # Färbe die Kanäle basierend auf dem Winkel der Bewegung\n",
    "    # Betrachte dein Video genau, die Flussrichtung der Bewegung bestimmt die Farbe!\n",
    "    mag, ang = cv2.cartToPolar(flow[:,:,0], flow[:,:,1],angleInDegrees=True)\n",
    "    hsv_mask[:,:,0] = ang/2\n",
    "    hsv_mask[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Konvertiere zurück zu BGR mit imshow von OpenCV\n",
    "    bgr = cv2.cvtColor(hsv_mask,cv2.COLOR_HSV2BGR)\n",
    "    cv2.imshow('frame2',bgr)\n",
    "    \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    \n",
    "    # Setze das vorherige Bild auf das nächste Bild für die Schleife\n",
    "    prvsImg = nextImg\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.cartToPolar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
